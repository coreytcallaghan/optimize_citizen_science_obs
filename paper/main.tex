\documentclass[9pt,twocolumn,twoside,lineno]{pnas-new}
% Use the lineno option to display guide line numbers if required.

\templatetype{pnasresearcharticle} % Choose template
% {pnasresearcharticle} = Template for a two-column research article
% {pnasmathematics} %= Template for a one-column mathematics article
% {pnasinvited} %= Template for a PNAS invited submission

\title{Optimizing the future of biodiversity sampling by citizen scientists}

% Use letters for affiliations, numbers to show equal authorship (if applicable) and to indicate the corresponding author
\author[a,b,1]{Corey T. Callaghan}
\author[c,]{Alistair G. B. Poore}
\author[b,a]{Richard E. Major}
\author[b,a]{Jodi J. L. Rowley}
\author[a,c]{William K. Cornwell}

\affil[a]{Centre for Ecosystem Science, School of Biological, Earth and Environmental Sciences, UNSW Sydney, Sydney, 2052, NSW, Australia}
\affil[b]{Australian Museum Research Institute, Australian Museum, Sydney, 2000, NSW, Australia}
\affil[c]{Ecology and Evolution Research Centre, School of Biological, Earth and Environmental Sciences, UNSW Sydney, Sydney, 2052, NSW, Australia}

% Please give the surname of the lead author for the running footer
\leadauthor{Callaghan}

% Please add here a significance statement to explain the relevance of your work
\significancestatement{Citizen scientists are increasingly monitoring biodiversity, but we need to better understand how to optimally sample biodiversity in time and space for intended outcomes, relying on citizen science data.}

% Please include corresponding author, author contribution and author declaration information
\authorcontributions{Please provide details of author contributions here.}
\authordeclaration{The authors have no conflict of interest to declare.}

\correspondingauthor{\textsuperscript{1}To whom correspondence should be addressed. E-mail: c.callaghan@unsw.edu.au}

% Keywords are not mandatory, but authors are strongly encouraged to provide them. If provided, please include two to five keywords, separated by the pipe symbol, e.g:
\keywords{biodiversity $|$ conservation $|$ citizen science $|$ optimal sampling $|$ eBird}

\begin{abstract}
Citizen science is so so important. yata yata yata
\end{abstract}

\dates{This manuscript was compiled on \today}
\doi{\url{www.pnas.org/cgi/doi/10.1073/pnas.XXXXXXXXXX}}

\begin{document}

\maketitle
\thispagestyle{firststyle}
\ifthenelse{\boolean{shortarticle}}{\ifthenelse{\boolean{singlecolumn}}{\abscontentformatted}{\abscontent}}{}

% If your first paragraph (i.e. with the \dropcap) contains a list environment (quote, quotation, theorem, definition, enumerate, itemize...), the line after the list may have some extra indentation. If this is the case, add \parshape=0 to the end of the list environment.
\dropcap{A}ssessing biodiversity trends in space and time is essential for conservation \cite{harrison2014assessing, wilson2011modelling, mcmahon2011improving, honrado2016fostering} \parshape=0. Reliable biodiversity estimates allow us to track our global progress in curbing biodiversity loss \cite{harrison2014assessing}. Unsurprisingly, reliable trend detection is usually derived from well-designed surveys in space and time \cite{harrison2014assessing, vellend2017estimates, kery2009trend}, that are long-term \cite{lindenmayer2012value, magurran2010long}. But scientific funding for long-term ecological and conservation research is rapidly disappearing [REFS???]. Increasingly, government agencies, scientific researchers, and conservationists are turning to citizen science data to help inform the state of biodiversity at local \cite{callaghan2015efficacy, theobald2015global, sullivan2017using, loss2015linking}, regional \cite{barlow2015citizen, fox2011new}, and global scales \cite{chandler2017contribution, pocock2018vision, cooper2014invisible}.

Citizen science --- the cooperation between a range of experts and non-experts  --- is an incredibly diverse field \cite{jordan2015citizen}. Projects generally fall along a continuum based on the level of associated structure \cite{kelling2019using, welvaert2016citizen}, ranging from unstructured (e.g., iNaturalist) to structured (U.K. Butterfly Monitoring Scheme). The level of structure, in turn, influences the biases and data quality concerns of a particular project. For instance, observer skill \cite{kelling2015can}, time-of-day, number of participants in a group, and technological capabilities of a participant may influence the data collected by some, but not necessarily all, citizen science projects. Generalizeable among citizen science projects, however, are various spatial and temporal biases \cite{boakes2010distorted, bird2014statistical}. Observers submitting observations on weekends \cite{courter2013weekend}, sampling near roads and human settlements \cite{kelling2015taking}, and observers visiting known 'hotspots' for biodiversity are all examples of spatial and temporal biases. Importantly, these biases are not restricted to citizen science projects. 'Professional scientists' also have biased sampling of biodiversity, highlighted by biased museum collections [REFS???].

Fortunately, in the case of broad-scale biodiversity data collected by citizen scientists, these various biases can generally be accounted for, statistically \cite{isaac2014statistics, robinson2018correcting}, by filtering or subsetting the data \cite{wiggins2011conservation}, pooling multiple data sources \cite{fithian2015bias}, or machine learning and hierarchical clustering techniques \cite{hochachka2012data, kelling2015taking}. Despite these biases, citizen science data have increased our knowledge on species distribution models \cite{bradsworth2017species, van2013opportunistic}, niche breadth \cite{tiago2017using}, biodiversity measurements \cite{stuart2017assessing, pocock2018vision}, phenological research \cite{la2014role, supp2015citizen}, invasive species detection \cite{pocock2017citizen, grason2018citizen}, and phylogeographical research \cite{bahls2014new, drury2019continent}. Still, estimating trends with citizen science data is best done with data from structured projects (i.e., less biases to account for) \cite{fox2011new}, but unstructured and semistructured projects are increasingly harnessed for trend detection \cite{walker2017using, kery2009trend, kery2010site, horns2018using, van2013occupancy, pagel2014quantifying}.

The number of ecological and environmental monitoring citizen science projects is increasing \cite{pocock2017diversity, theobald2015global}, highlighting the potential that citizen science holds for the future of ecology, conservation, and natural resource management \cite{pocock2018vision, silvertown2009new, soroye2018opportunistic, mckinley2017citizen}. But a major obstacle in the future use of citizen science data remains understanding how to best extract information from 'noisy' citizen science datasets \cite{parrish2018exposing}.

However, these 'big-data' statistical approaches \cite{kelling2015taking} are most applicable for data originating from large, successful citizen science projects. What about projects that are just starting? Or projects focusing on taxa that are less popular with the general public \cite{mair2016explaining, ward2014understanding}? Are there optimal strategies for sampling in space and time, which are best able to contribute to estimating biodiversity trends?

Here, we investigate these questions with a specific objective: investigate how spatial and temporal sampling influences trend detection of biodiversity. Our approach is site-specific and dynamic: we are interested in the parameters that influence the marginal value of a given citizen science observation for a particular day. Here, we summarize the parameters in space and time which we hyptohesized would influence the value of a citizen science observation.

\begin{itemize}
  \item \textbf{Whether a site was sampled}: if a site had been previously sampled or not. We predicted that unsampled sites would be marginally more valuable than sampled previously sampled sites.
  \item \textbf{Median sampling interval}: the median of the distribution of waiting times between samples at a site. We predicted that the median sampling interval would be positively associated with the value of a citizen science observation. I.e., observations from sites with high median waiting times would be more valuable than observations from sites with low median waiting times.
  \item \textbf{Days since last sample}: the number of days between samples at a site. We predicted that the days since the last sample would positively associate with the value of a citizen science observation.
  \item \textbf{Distance to the nearest sampled site}: the distance between the site in question and the nearest sampled site. We hypothesized that for the distance to the nearest sampled site would be positively associated with the value of a citizen science observation.
  \item \textbf{Nearest neighbor sampling interval}: the median sampling interval of the nearest neighbor. We hypothesized that this would be positively influence the value of a observation, whereby well-sampled areas (i.e., multiple sites near each other with low median sampling intervals) would have lower value observations.
  \item \textbf{Number of unique days sampled}: the total number of unique days sampled for a given site. We predicted that the total number of unique days would be positively associated with the value of an observation, whereby sites with lots of observations would receive value given the long-term data originating from them.
\end{itemize}

We illustrate our approach using a popular citizen science project --- eBird \cite{sullivan2009ebird} --- and data from the Greater Sydney Region, NSW, Australia.

\section*{Results and Discussion}
We found weak evidence that unsampled sites were more marginally valuable than unsampled sites across grid sizes (Fig. S1), noting, however, that there were no unsampled grids in the 50 km grid cell size. This suggests that stratified sampling --- an approach which aims for equal sampling among grids or sites --- [REF] may not be the most applicable approach for detecting trends using citizen science data. This also suggests that citizen scientists generally are sufficiently sampling the appropriate areas: local knowledge indicates where birders should go birding.

However, there are still parameters that are significantly important for the marginal value of a citizen science observation (PARAMETER ESTIMATES FIGURE). At all four grid sizes, days since the last sample was positively associated with the marginal value of a citizen science observation. For all but the 10 km grid size, distance to the nearest sampled grid was positively associated with the marginal value of a citizen science observation. Conversely, the results for median sampling interval were negatively associated with the value of a citizen science observation. Nearest neighbor sampling interval had relatively weak influence on the value of a citizen science observation, compared with other parameters, as did the number of unique days sampled for a given grid.

These results suggest that the value of a given citizen science observation can indeed be predicted based on temporal and spatial sampling. Through time, the longer a grid goes unsampled (i.e., days since last sample), that grid's marginal value will continue to increase. Similarly, this is synergistic with the distance to the nearest sampled grid, whereby the further away from a sampled grid an observation is, the more valuable that observation is.

We were also able to use our fitted models to predict the expected value of a given citizen science observation, dynamically, for any given day. This approach required us to look backward first, in order to predict future values. (STATIC MAP FIGURE).


Citizen science projects need to continuously adapt to be successful, and to better inform conservation science. Even if a project may not have specific objectives/goals, it is important for the project to adapt to particular questions.

The same approach is robust to spatial scale: whether a citizen science project is global, regional, or carried out in the constraints of a local park, the site can be gridded and observations can then be guided into the future.


We envision a dynamic approach in the future of citizen science projects, which would ultimately guide participants to sites which \textit{should} be sampled on any given day. For every day, a citizen scientists can be presented with a map, showing the highest valued sites that should be visited. Imagine visitor centers at National Parks and

Feedback to citizen science participants is important! Imagine visitor centers across the world at national parks or urban greenspaces providing users with a localized map showing which trail someone should visit if they are interested in contributing to citizen science. More broadly, this approach could be applied to anyone in the world. The global pull of ecotourism is increasing exponentially, allowing the the potential for people to contribute to local biodiversity knowledge in areas that are traditionally undersampled.

This approach evolves citizen science projects, moving past leaderboards which show the number of species or number of records for a participant, and show the 'value' of a participant's observations.

Here, our framework focused on a specific statistical outcome: trend detection. Many other ecological outcomes arise from citizen science, including species distribution models, phylogeographical research, invasive species detection, or phenological research. These potential outcomes will have different optimal sampling strategies in space and time. We note that our framework is robust, with the necessary piece of information being a statistical model to extract leverage.



This approach relies on statistical leverage, assigning every citizen science observation a measure of influence that influences a statistical model.

- Looking forward but using the past
- We only looked at trend detection, but many other models can be used in this process (e.g., species distribution models)
- Other potentials for this general approach (identifying outliers in the dataset or misidentified species)

\matmethods{Please describe your materials and methods here. This can be more than one paragraph, and may contain subsections and equations as required. Authors should include a statement in the methods section describing how readers will be able to access the data in the paper.

\subsection*{Study region} We illustrate our concepts throughout the Greater Sydney Region, and we gridded the region into 411 grids, all of which are ~ km. We used the R statistical environment to carry out all analyses.

\subsection*{eBird data} We downloaded the eBird basic dataset (VERSION), and subsetted the data between January 1st, 2010 to December 31st, 2018. eBird collects data in the form of 'checklists' --- a list of all species identified (audibly or visually) for a given spatiotemporal coordinates. eBird relies on an extensive network of regional reviewers who are local experts of the avifauna [REF]

\subsection*{Trend detection model} For illustration purposes, we fitted a simple generalized linear model, based on presence/absence for each of 274 species --- those of which had > 20 observations in the region throughout the study period. The GLM took the form of: XXXXXX. County was included to add a spatial representation throughout the Greater Sydney Region, while we included the length of the list in the model as an offset to account for the effort associated with each individual eBird checklist.

We acknowledge that a number of different models can be fit which assesses trend detection [REFS], and biases can be accounted for in a variety of ways [REFS]. These models were fitted for the period between 2010-2018.

\subsection*{Statistical leverage} Statistical leverage measures the influence of a particular observation on the independent variable [REFS]. In other words, it is a measure of how much an observation influences the results of an observation. In our instance, because we had multiple predictor variables in our GLMs, we used dfBeta as a measure of statistical leverage. dfBeta can be calculated for a given parameter in a regression model.

For each species (N=274) we calculated the dfBeta for each of the 29,055 observations used for each model. Then for every checklist assessed in the model, we took the sum of the absolute value of the dfBetas for that checklist as a measure of a checklist's leverage in understanding species' trends throughout the Greater Sydney Region.

\subsection*{Parameter calculation} For each day in 2018 (N=365), for each grid, we dynamically calculated the following parameters, based on sampling: (1) whether a grid cell was sampled, (2) the distance to the nearest sampled grid cell, (3) the median sampling interval of a grid cell, (4) the median sampling interval of the nearest sampled grid cell, (5) days since the last sample in a grid cell, and (6) the duration of sampling in a grid cell --- most recent sample minus the earliest sampled date. These are some hypothesized parameters which we felt would influence the relative value of a given sampling event.

We then subsetted the leverage calculations (see above) for each of the days in 2018, given we know where people sampled, relative to the parameters for each of the grids. We ran a linear regression to parameterize what parameters had the greatest impact on the leverage of a given observation.

\subsection*{Expected leverage calculation} We XXXXX.

\subsection*{Data availability}


}

\showmatmethods{} % Display the Materials and Methods section

\acknow{We thank the countless citizen scientists who are contributing data that is continuously increasing our collective knowledge of biodiversity.}

\showacknow{} % Display the acknowledgments section

% Bibliography
\bibliography{refs}

\end{document}
